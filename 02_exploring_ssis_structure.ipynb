{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring SSIS Structure in Memgraph\n",
    "\n",
    "This notebook focuses on understanding how SSIS components are represented in the graph and how to navigate the SSIS Northwind structure.\n",
    "\n",
    "## What We'll Learn\n",
    "- SSIS package structure in graph format\n",
    "- How operations, tables, and connections are modeled\n",
    "- Data flow analysis through the graph\n",
    "- Package dependencies and execution order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - same as notebook 01\n",
    "import mgclient\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Connect to Memgraph\n",
    "mg = mgclient.connect(host='localhost', port=7687, username='', password='')\n",
    "print(\"✅ Connected to Memgraph\")\n",
    "\n",
    "def execute_query(query, description=None):\n",
    "    \"\"\"Execute a Cypher query and return results as DataFrame.\"\"\"\n",
    "    if description:\n",
    "        print(f\"\\n🔍 {description}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    cursor = mg.cursor()\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    if results:\n",
    "        columns = [desc.name for desc in cursor.description] if cursor.description else ['result']\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "        print(f\"Found {len(df)} results\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: SSIS Package Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed information about SSIS packages\n",
    "packages_df = execute_query(\n",
    "    \"\"\"MATCH (p:Node {node_type: 'pipeline'}) \n",
    "       RETURN p.name as package_name, \n",
    "              p.id as package_id,\n",
    "              p.properties as properties\n",
    "       ORDER BY p.name\"\"\",\n",
    "    \"Detailed SSIS package information\"\n",
    ")\n",
    "\n",
    "print(f\"\\n📦 Found {len(packages_df)} SSIS packages:\")\n",
    "for _, pkg in packages_df.iterrows():\n",
    "    print(f\"  • {pkg['package_name']}\")\n",
    "    \n",
    "display(packages_df[['package_name', 'package_id']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at package properties to understand what metadata is available\n",
    "if not packages_df.empty:\n",
    "    sample_package = packages_df.iloc[0]\n",
    "    print(f\"\\n🔍 Sample Package Properties: {sample_package['package_name']}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        properties = json.loads(sample_package['properties']) if isinstance(sample_package['properties'], str) else sample_package['properties']\n",
    "        for key, value in properties.items():\n",
    "            if isinstance(value, str) and len(value) > 100:\n",
    "                print(f\"{key}: {value[:100]}...\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not parse properties: {e}\")\n",
    "        print(f\"Raw properties: {sample_package['properties']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Operations Within Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find operations and which packages they belong to\n",
    "operations_df = execute_query(\n",
    "    \"\"\"MATCH (pkg:Node {node_type: 'pipeline'})-[:CONTAINS]->(op:Node {node_type: 'operation'})\n",
    "       RETURN pkg.name as package_name, \n",
    "              op.name as operation_name,\n",
    "              op.id as operation_id\n",
    "       ORDER BY pkg.name, op.name\"\"\",\n",
    "    \"Operations within SSIS packages\"\n",
    ")\n",
    "\n",
    "if not operations_df.empty:\n",
    "    print(f\"\\n⚙️ Operations by Package:\")\n",
    "    for package in operations_df['package_name'].unique():\n",
    "        ops = operations_df[operations_df['package_name'] == package]\n",
    "        print(f\"\\n📦 {package} ({len(ops)} operations):\")\n",
    "        for _, op in ops.head(5).iterrows():  # Show first 5 operations\n",
    "            print(f\"  • {op['operation_name']}\")\n",
    "        if len(ops) > 5:\n",
    "            print(f\"  ... and {len(ops) - 5} more operations\")\n",
    "\n",
    "display(operations_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualization of packages and their operation counts\n",
    "if not operations_df.empty:\n",
    "    ops_per_package = operations_df.groupby('package_name').size().reset_index(name='operation_count')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=ops_per_package, x='operation_count', y='package_name')\n",
    "    plt.title('Number of Operations per SSIS Package')\n",
    "    plt.xlabel('Number of Operations')\n",
    "    plt.ylabel('Package Name')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n📊 Operation Count Statistics:\")\n",
    "    print(f\"Total Operations: {len(operations_df)}\")\n",
    "    print(f\"Average Operations per Package: {ops_per_package['operation_count'].mean():.1f}\")\n",
    "    print(f\"Package with Most Operations: {ops_per_package.loc[ops_per_package['operation_count'].idxmax(), 'package_name']} ({ops_per_package['operation_count'].max()} ops)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Assets and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore tables and data assets\n",
    "tables_df = execute_query(\n",
    "    \"\"\"MATCH (t:Node {node_type: 'table'})\n",
    "       RETURN t.name as table_name, \n",
    "              t.id as table_id,\n",
    "              t.properties as properties\n",
    "       ORDER BY t.name\"\"\",\n",
    "    \"Data assets and tables in the SSIS graph\"\n",
    ")\n",
    "\n",
    "print(f\"\\n🗃️ Found {len(tables_df)} tables/data assets:\")\n",
    "if not tables_df.empty:\n",
    "    for _, table in tables_df.head(10).iterrows():\n",
    "        print(f\"  • {table['table_name']}\")\n",
    "    if len(tables_df) > 10:\n",
    "        print(f\"  ... and {len(tables_df) - 10} more tables\")\n",
    "\n",
    "display(tables_df[['table_name', 'table_id']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Data Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data flows (operations reading from or writing to tables)\n",
    "data_flows_df = execute_query(\n",
    "    \"\"\"MATCH (op:Node {node_type: 'operation'})-[r:READS_FROM|WRITES_TO]->(table:Node {node_type: 'table'})\n",
    "       RETURN op.name as operation_name,\n",
    "              type(r) as flow_type,\n",
    "              table.name as table_name\n",
    "       ORDER BY table.name, op.name\"\"\",\n",
    "    \"Data flows between operations and tables\"\n",
    ")\n",
    "\n",
    "if not data_flows_df.empty:\n",
    "    print(f\"\\n💾 Data Flow Summary:\")\n",
    "    flow_summary = data_flows_df['flow_type'].value_counts()\n",
    "    for flow_type, count in flow_summary.items():\n",
    "        print(f\"  • {flow_type}: {count} connections\")\n",
    "    \n",
    "    print(f\"\\n🔄 Sample Data Flows:\")\n",
    "    for _, flow in data_flows_df.head(10).iterrows():\n",
    "        print(f\"  • {flow['operation_name']} --[{flow['flow_type']}]--> {flow['table_name']}\")\n",
    "\n",
    "display(data_flows_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find tables that are used by multiple operations (shared resources)\n",
    "shared_tables_df = execute_query(\n",
    "    \"\"\"MATCH (op:Node {node_type: 'operation'})-[r:READS_FROM|WRITES_TO]->(table:Node {node_type: 'table'})\n",
    "       WITH table, collect(DISTINCT op.name) as operations, count(DISTINCT op) as operation_count\n",
    "       WHERE operation_count > 1\n",
    "       RETURN table.name as table_name,\n",
    "              operation_count,\n",
    "              operations\n",
    "       ORDER BY operation_count DESC\"\"\",\n",
    "    \"Tables shared by multiple operations (potential bottlenecks)\"\n",
    ")\n",
    "\n",
    "if not shared_tables_df.empty:\n",
    "    print(f\"\\n⚠️ Shared Tables (Potential Bottlenecks):\")\n",
    "    for _, table in shared_tables_df.iterrows():\n",
    "        print(f\"  • {table['table_name']}: used by {table['operation_count']} operations\")\n",
    "        operations_list = table['operations'][:3]  # Show first 3 operations\n",
    "        print(f\"    Operations: {', '.join(operations_list)}{'...' if len(table['operations']) > 3 else ''}\")\n",
    "        print()\n",
    "\n",
    "display(shared_tables_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Package Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for cross-package dependencies\n",
    "cross_package_deps_df = execute_query(\n",
    "    \"\"\"MATCH (pkg1:Node {node_type: 'pipeline'})-[r:DEPENDS_ON]->(pkg2:Node {node_type: 'pipeline'})\n",
    "       RETURN pkg1.name as dependent_package,\n",
    "              pkg2.name as dependency_package,\n",
    "              type(r) as relationship_type\n",
    "       ORDER BY pkg1.name\"\"\",\n",
    "    \"Cross-package dependencies\"\n",
    ")\n",
    "\n",
    "if not cross_package_deps_df.empty:\n",
    "    print(f\"\\n🔗 Cross-Package Dependencies:\")\n",
    "    for _, dep in cross_package_deps_df.iterrows():\n",
    "        print(f\"  • {dep['dependent_package']} depends on {dep['dependency_package']}\")\n",
    "    \n",
    "    display(cross_package_deps_df)\n",
    "else:\n",
    "    print(\"\\n🔗 No direct cross-package dependencies found.\")\n",
    "    print(\"This could mean packages are independent or dependencies are implicit through shared resources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Look for implicit dependencies through shared tables\n",
    "implicit_deps_df = execute_query(\n",
    "    \"\"\"MATCH (pkg1:Node {node_type: 'pipeline'})-[:CONTAINS]->(op1:Node {node_type: 'operation'})-[:WRITES_TO]->(table:Node {node_type: 'table'})<-[:READS_FROM]-(op2:Node {node_type: 'operation'})<-[:CONTAINS]-(pkg2:Node {node_type: 'pipeline'})\n",
    "       WHERE pkg1.name <> pkg2.name\n",
    "       RETURN DISTINCT pkg1.name as writer_package,\n",
    "              pkg2.name as reader_package,\n",
    "              table.name as shared_table\n",
    "       ORDER BY shared_table, writer_package\"\"\",\n",
    "    \"Implicit dependencies through shared tables\"\n",
    ")\n",
    "\n",
    "if not implicit_deps_df.empty:\n",
    "    print(f\"\\n🔄 Implicit Dependencies (via shared tables):\")\n",
    "    for _, dep in implicit_deps_df.head(10).iterrows():\n",
    "        print(f\"  • {dep['writer_package']} writes to {dep['shared_table']}, read by {dep['reader_package']}\")\n",
    "    \n",
    "    display(implicit_deps_df.head(10))\n",
    "else:\n",
    "    print(\"\\n🔄 No implicit dependencies through shared tables found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Connection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze database connections\n",
    "connections_df = execute_query(\n",
    "    \"\"\"MATCH (c:Node {node_type: 'connection'})\n",
    "       RETURN c.name as connection_name,\n",
    "              c.id as connection_id,\n",
    "              c.properties as properties\n",
    "       ORDER BY c.name\"\"\",\n",
    "    \"Database connections in the SSIS graph\"\n",
    ")\n",
    "\n",
    "print(f\"\\n🔌 Found {len(connections_df)} connections:\")\n",
    "if not connections_df.empty:\n",
    "    for _, conn in connections_df.iterrows():\n",
    "        print(f\"  • {conn['connection_name']}\")\n",
    "    \n",
    "    display(connections_df[['connection_name', 'connection_id']])\n",
    "else:\n",
    "    print(\"No explicit connection nodes found.\")\n",
    "    print(\"Connections might be embedded in operation properties.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find operations that use connections\n",
    "op_connections_df = execute_query(\n",
    "    \"\"\"MATCH (op:Node {node_type: 'operation'})-[r:USES_CONNECTION]->(conn:Node {node_type: 'connection'})\n",
    "       RETURN op.name as operation_name,\n",
    "              conn.name as connection_name,\n",
    "              type(r) as relationship_type\n",
    "       ORDER BY conn.name, op.name\"\"\",\n",
    "    \"Operations using database connections\"\n",
    ")\n",
    "\n",
    "if not op_connections_df.empty:\n",
    "    print(f\"\\n🔗 Operation-Connection Relationships:\")\n",
    "    conn_usage = op_connections_df.groupby('connection_name').size().reset_index(name='usage_count')\n",
    "    \n",
    "    for _, usage in conn_usage.iterrows():\n",
    "        print(f\"  • {usage['connection_name']}: used by {usage['usage_count']} operations\")\n",
    "    \n",
    "    display(op_connections_df.head(10))\n",
    "else:\n",
    "    print(\"\\n🔗 No explicit operation-connection relationships found.\")\n",
    "    print(\"This is normal if connections are embedded within operations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Graph Structure Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary of the SSIS graph structure\n",
    "print(\"📊 SSIS Northwind Graph Structure Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Node counts by type\n",
    "node_summary_df = execute_query(\n",
    "    \"MATCH (n) RETURN n.node_type as node_type, count(n) as count ORDER BY count DESC\"\n",
    ")\n",
    "\n",
    "print(\"\\n📦 Node Types:\")\n",
    "total_nodes = 0\n",
    "for _, row in node_summary_df.iterrows():\n",
    "    if row['node_type'] not in ['materialized_view', 'graph_metadata']:  # Exclude analytics nodes\n",
    "        print(f\"  • {row['node_type']}: {row['count']} nodes\")\n",
    "        total_nodes += row['count']\n",
    "\n",
    "# Relationship counts\n",
    "rel_summary_df = execute_query(\n",
    "    \"MATCH ()-[r]->() RETURN type(r) as relationship_type, count(r) as count ORDER BY count DESC\"\n",
    ")\n",
    "\n",
    "print(\"\\n🔗 Relationship Types:\")\n",
    "total_relationships = 0\n",
    "for _, row in rel_summary_df.iterrows():\n",
    "    print(f\"  • {row['relationship_type']}: {row['count']} relationships\")\n",
    "    total_relationships += row['count']\n",
    "\n",
    "print(f\"\\n📈 Totals:\")\n",
    "print(f\"  • Total SSIS Nodes: {total_nodes}\")\n",
    "print(f\"  • Total Relationships: {total_relationships}\")\n",
    "print(f\"  • Graph Density: {total_relationships / (total_nodes * (total_nodes - 1)):.4f}\" if total_nodes > 1 else \"  • Graph Density: N/A\")\n",
    "\n",
    "# Create visualizations\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Node types pie chart\n",
    "ssis_nodes = node_summary_df[~node_summary_df['node_type'].isin(['materialized_view', 'graph_metadata'])]\n",
    "ax1.pie(ssis_nodes['count'], labels=ssis_nodes['node_type'], autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('SSIS Node Types Distribution')\n",
    "\n",
    "# Relationship types bar chart\n",
    "sns.barplot(data=rel_summary_df, x='count', y='relationship_type', ax=ax2)\n",
    "ax2.set_title('Relationship Types Count')\n",
    "ax2.set_xlabel('Number of Relationships')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you understand the SSIS graph structure, you can:\n",
    "\n",
    "1. **Explore Analytics-Ready Features** - Open `03_analytics_ready_features.ipynb` to learn about materialized views\n",
    "2. **Advanced Queries** - Open `04_advanced_queries.ipynb` for complex analysis patterns\n",
    "3. **Migration Analysis** - Open `05_migration_analysis.ipynb` for practical migration scenarios\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- SSIS packages are represented as `pipeline` nodes\n",
    "- Operations within packages are `operation` nodes connected via `CONTAINS` relationships\n",
    "- Data flows are modeled as `READS_FROM` and `WRITES_TO` relationships\n",
    "- Shared resources (tables used by multiple operations) can indicate potential bottlenecks\n",
    "- The graph structure reflects the actual SSIS package architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}